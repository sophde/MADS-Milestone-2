{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "wiki_difficulty_w2v.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_svpJY9L1J-"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqo6Aj9eL1KB",
        "outputId": "378362df-d779-4a6c-85a0-d34fb9ac6e13"
      },
      "source": [
        "data = pd.read_csv('WikiLarge_Train.csv', encoding=\"utf-8\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is manuscript evidence that Austen conti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Before Persephone was released to Hermes , who...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cogeneration plants are commonly found in dist...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  label\n",
              "0  There is manuscript evidence that Austen conti...      1\n",
              "1  In a remarkable comparative analysis , Mandaea...      1\n",
              "2  Before Persephone was released to Hermes , who...      1\n",
              "3  Cogeneration plants are commonly found in dist...      1\n",
              "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-P2wyVPL1KC"
      },
      "source": [
        "def clean(data):\n",
        "# create a new column of text data, lower case all words \n",
        "    data[\"cleaned_text\"] = data['original_text'].str.lower()\n",
        "\n",
        "    # remove \"-LRB-\", \"-LRB-\", non-alphabets and non-ascii characters\n",
        "    data['cleaned_text'] = data['cleaned_text'].str.replace(\"-lrb-\", '')\n",
        "    data['cleaned_text'] = data['cleaned_text'].str.replace(\"-rrb-\", '')\n",
        "    data[\"cleaned_text\"] = data[\"cleaned_text\"].str.encode('ascii', 'ignore').str.decode('ascii')\n",
        "#     data[\"cleaned_text\"] = data[\"cleaned_text\"].str.replace(',', '')\n",
        "#     data[\"cleaned_text\"] = data[\"cleaned_text\"].str.replace('.', '')\n",
        "#     data[\"cleaned_text\"] = data[\"cleaned_text\"].str.replace('` `', '')\n",
        "\n",
        "    # remove space >1\n",
        "    data[\"cleaned_text\"] = data[\"cleaned_text\"].str.replace('[\\s]{2,}', ' ')\n",
        "\n",
        "    # remove space at the begining and the end of each sentence\n",
        "    data[\"cleaned_text\"] = data[\"cleaned_text\"].str.strip()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgAGChFiL1KC",
        "outputId": "0c1bbdfd-e7ab-4643-8d20-4c272373bee1"
      },
      "source": [
        "# cleaned data\n",
        "data = clean(data)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is manuscript evidence that Austen conti...</td>\n",
              "      <td>1</td>\n",
              "      <td>there is manuscript evidence that austen conti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
              "      <td>1</td>\n",
              "      <td>in a remarkable comparative analysis , mandaea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Before Persephone was released to Hermes , who...</td>\n",
              "      <td>1</td>\n",
              "      <td>before persephone was released to hermes , who...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cogeneration plants are commonly found in dist...</td>\n",
              "      <td>1</td>\n",
              "      <td>cogeneration plants are commonly found in dist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
              "      <td>1</td>\n",
              "      <td>geneva , ; , ; , ; ; is the second-most-populo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  label  \\\n",
              "0  There is manuscript evidence that Austen conti...      1   \n",
              "1  In a remarkable comparative analysis , Mandaea...      1   \n",
              "2  Before Persephone was released to Hermes , who...      1   \n",
              "3  Cogeneration plants are commonly found in dist...      1   \n",
              "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  there is manuscript evidence that austen conti...  \n",
              "1  in a remarkable comparative analysis , mandaea...  \n",
              "2  before persephone was released to hermes , who...  \n",
              "3  cogeneration plants are commonly found in dist...  \n",
              "4  geneva , ; , ; , ; ; is the second-most-populo...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YykfEGrL1KD"
      },
      "source": [
        "# nltk.word_tokenize(data.iloc[1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni39LGTlL1KD",
        "outputId": "d0801cf8-ef37-472e-9602-d0ffcb97c9b4"
      },
      "source": [
        "data['token_text'] = data[\"cleaned_text\"].apply(lambda x: nltk.word_tokenize(x))\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is manuscript evidence that Austen conti...</td>\n",
              "      <td>1</td>\n",
              "      <td>there is manuscript evidence that austen conti...</td>\n",
              "      <td>[there, is, manuscript, evidence, that, austen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
              "      <td>1</td>\n",
              "      <td>in a remarkable comparative analysis , mandaea...</td>\n",
              "      <td>[in, a, remarkable, comparative, analysis, ,, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Before Persephone was released to Hermes , who...</td>\n",
              "      <td>1</td>\n",
              "      <td>before persephone was released to hermes , who...</td>\n",
              "      <td>[before, persephone, was, released, to, hermes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cogeneration plants are commonly found in dist...</td>\n",
              "      <td>1</td>\n",
              "      <td>cogeneration plants are commonly found in dist...</td>\n",
              "      <td>[cogeneration, plants, are, commonly, found, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
              "      <td>1</td>\n",
              "      <td>geneva , ; , ; , ; ; is the second-most-populo...</td>\n",
              "      <td>[geneva, ,, ;, ,, ;, ,, ;, ;, is, the, second-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  label  \\\n",
              "0  There is manuscript evidence that Austen conti...      1   \n",
              "1  In a remarkable comparative analysis , Mandaea...      1   \n",
              "2  Before Persephone was released to Hermes , who...      1   \n",
              "3  Cogeneration plants are commonly found in dist...      1   \n",
              "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  there is manuscript evidence that austen conti...   \n",
              "1  in a remarkable comparative analysis , mandaea...   \n",
              "2  before persephone was released to hermes , who...   \n",
              "3  cogeneration plants are commonly found in dist...   \n",
              "4  geneva , ; , ; , ; ; is the second-most-populo...   \n",
              "\n",
              "                                          token_text  \n",
              "0  [there, is, manuscript, evidence, that, austen...  \n",
              "1  [in, a, remarkable, comparative, analysis, ,, ...  \n",
              "2  [before, persephone, was, released, to, hermes...  \n",
              "3  [cogeneration, plants, are, commonly, found, i...  \n",
              "4  [geneva, ,, ;, ,, ;, ,, ;, ;, is, the, second-...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yICJVhqL1KD"
      },
      "source": [
        "def lemmatization(row):\n",
        "    #make sure nltk.download('stopwords') and nltk.download('wordnet') work \n",
        "    stop = list(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    \n",
        "    token_words= word_tokenize(row)\n",
        "    token_words = [word for word in token_words if not word in stop]\n",
        "    stem_sentence = []\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(lemmatizer.lemmatize(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI-l4qpXL1KE"
      },
      "source": [
        "data[\"length\"] = data['cleaned_text'].apply(lambda x: len(lemmatization(x).strip().split(\" \")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug9QP8aqL1KE",
        "outputId": "2d03d005-06b3-4d57-f76f-e77ea4521862"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>token_text</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is manuscript evidence that Austen conti...</td>\n",
              "      <td>1</td>\n",
              "      <td>there is manuscript evidence that austen conti...</td>\n",
              "      <td>[there, is, manuscript, evidence, that, austen...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
              "      <td>1</td>\n",
              "      <td>in a remarkable comparative analysis , mandaea...</td>\n",
              "      <td>[in, a, remarkable, comparative, analysis, ,, ...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Before Persephone was released to Hermes , who...</td>\n",
              "      <td>1</td>\n",
              "      <td>before persephone was released to hermes , who...</td>\n",
              "      <td>[before, persephone, was, released, to, hermes...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cogeneration plants are commonly found in dist...</td>\n",
              "      <td>1</td>\n",
              "      <td>cogeneration plants are commonly found in dist...</td>\n",
              "      <td>[cogeneration, plants, are, commonly, found, i...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
              "      <td>1</td>\n",
              "      <td>geneva , ; , ; , ; ; is the second-most-populo...</td>\n",
              "      <td>[geneva, ,, ;, ,, ;, ,, ;, ;, is, the, second-...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  label  \\\n",
              "0  There is manuscript evidence that Austen conti...      1   \n",
              "1  In a remarkable comparative analysis , Mandaea...      1   \n",
              "2  Before Persephone was released to Hermes , who...      1   \n",
              "3  Cogeneration plants are commonly found in dist...      1   \n",
              "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  there is manuscript evidence that austen conti...   \n",
              "1  in a remarkable comparative analysis , mandaea...   \n",
              "2  before persephone was released to hermes , who...   \n",
              "3  cogeneration plants are commonly found in dist...   \n",
              "4  geneva , ; , ; , ; ; is the second-most-populo...   \n",
              "\n",
              "                                          token_text  length  \n",
              "0  [there, is, manuscript, evidence, that, austen...      25  \n",
              "1  [in, a, remarkable, comparative, analysis, ,, ...      17  \n",
              "2  [before, persephone, was, released, to, hermes...      23  \n",
              "3  [cogeneration, plants, are, commonly, found, i...      34  \n",
              "4  [geneva, ,, ;, ,, ;, ,, ;, ;, is, the, second-...      19  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDSZiIg-L1KE"
      },
      "source": [
        "def create_ngram(n, token_row):\n",
        "    ngram = []\n",
        "    ngram.extend((ngrams(token_row, n)))\n",
        "    return ngram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s6PfB9ML1KF"
      },
      "source": [
        "data['bigram'] = data['token_text'].apply(lambda x: create_ngram(2,x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1yOwYoSL1KF"
      },
      "source": [
        "# data.iloc[:3,3].apply(lambda x: x.extend(create_ngram(2,x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdOA4_UPL1KF",
        "outputId": "68b0c167-4ec8-43be-fac4-56b1275abca9"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>token_text</th>\n",
              "      <th>length</th>\n",
              "      <th>bigram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There is manuscript evidence that Austen conti...</td>\n",
              "      <td>1</td>\n",
              "      <td>there is manuscript evidence that austen conti...</td>\n",
              "      <td>[there, is, manuscript, evidence, that, austen...</td>\n",
              "      <td>25</td>\n",
              "      <td>[(there, is), (is, manuscript), (manuscript, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
              "      <td>1</td>\n",
              "      <td>in a remarkable comparative analysis , mandaea...</td>\n",
              "      <td>[in, a, remarkable, comparative, analysis, ,, ...</td>\n",
              "      <td>17</td>\n",
              "      <td>[(in, a), (a, remarkable), (remarkable, compar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Before Persephone was released to Hermes , who...</td>\n",
              "      <td>1</td>\n",
              "      <td>before persephone was released to hermes , who...</td>\n",
              "      <td>[before, persephone, was, released, to, hermes...</td>\n",
              "      <td>23</td>\n",
              "      <td>[(before, persephone), (persephone, was), (was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cogeneration plants are commonly found in dist...</td>\n",
              "      <td>1</td>\n",
              "      <td>cogeneration plants are commonly found in dist...</td>\n",
              "      <td>[cogeneration, plants, are, commonly, found, i...</td>\n",
              "      <td>34</td>\n",
              "      <td>[(cogeneration, plants), (plants, are), (are, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
              "      <td>1</td>\n",
              "      <td>geneva , ; , ; , ; ; is the second-most-populo...</td>\n",
              "      <td>[geneva, ,, ;, ,, ;, ,, ;, ;, is, the, second-...</td>\n",
              "      <td>19</td>\n",
              "      <td>[(geneva, ,), (,, ;), (;, ,), (,, ;), (;, ,), ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       original_text  label  \\\n",
              "0  There is manuscript evidence that Austen conti...      1   \n",
              "1  In a remarkable comparative analysis , Mandaea...      1   \n",
              "2  Before Persephone was released to Hermes , who...      1   \n",
              "3  Cogeneration plants are commonly found in dist...      1   \n",
              "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
              "\n",
              "                                        cleaned_text  \\\n",
              "0  there is manuscript evidence that austen conti...   \n",
              "1  in a remarkable comparative analysis , mandaea...   \n",
              "2  before persephone was released to hermes , who...   \n",
              "3  cogeneration plants are commonly found in dist...   \n",
              "4  geneva , ; , ; , ; ; is the second-most-populo...   \n",
              "\n",
              "                                          token_text  length  \\\n",
              "0  [there, is, manuscript, evidence, that, austen...      25   \n",
              "1  [in, a, remarkable, comparative, analysis, ,, ...      17   \n",
              "2  [before, persephone, was, released, to, hermes...      23   \n",
              "3  [cogeneration, plants, are, commonly, found, i...      34   \n",
              "4  [geneva, ,, ;, ,, ;, ,, ;, ;, is, the, second-...      19   \n",
              "\n",
              "                                              bigram  \n",
              "0  [(there, is), (is, manuscript), (manuscript, e...  \n",
              "1  [(in, a), (a, remarkable), (remarkable, compar...  \n",
              "2  [(before, persephone), (persephone, was), (was...  \n",
              "3  [(cogeneration, plants), (plants, are), (are, ...  \n",
              "4  [(geneva, ,), (,, ;), (;, ,), (,, ;), (;, ,), ...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2XQ24zsL1KF"
      },
      "source": [
        "# train dataset 80%, test dataset 20%\n",
        "X = data[['token_text','bigram',\"length\"]]\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVfSlMidL1KG",
        "outputId": "be934f38-cfc1-4e90-ffb8-158d509ea952"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(333414, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVgHV_0BL1KG",
        "outputId": "21b12840-9072-44f4-8d3d-9a4e985051d5"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_text</th>\n",
              "      <th>bigram</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>304501</th>\n",
              "      <td>[1979-80, buffalo, sabres, nhl, 32, 1880, 74, ...</td>\n",
              "      <td>[(1979-80, buffalo), (buffalo, sabres), (sabre...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162313</th>\n",
              "      <td>[diseases, lentils, in, culture, lentils, are,...</td>\n",
              "      <td>[(diseases, lentils), (lentils, in), (in, cult...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336845</th>\n",
              "      <td>[railroads, ,, like, the, lehigh, valley, rail...</td>\n",
              "      <td>[(railroads, ,), (,, like), (like, the), (the,...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150625</th>\n",
              "      <td>[an, example, of, this, would, be, an, individ...</td>\n",
              "      <td>[(an, example), (example, of), (of, this), (th...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40240</th>\n",
              "      <td>[both, the, matanuska, and, susitna, rivers, h...</td>\n",
              "      <td>[(both, the), (the, matanuska), (matanuska, an...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259178</th>\n",
              "      <td>[after, the, germans, invaded, norway, in, apr...</td>\n",
              "      <td>[(after, the), (the, germans), (germans, invad...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365838</th>\n",
              "      <td>[july, 28, -, henry, bennet, ,, 1st, earl, of,...</td>\n",
              "      <td>[(july, 28), (28, -), (-, henry), (henry, benn...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>[pancake, restaurants, are, popular, family, r...</td>\n",
              "      <td>[(pancake, restaurants), (restaurants, are), (...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146867</th>\n",
              "      <td>[a, cycling, domestique]</td>\n",
              "      <td>[(a, cycling), (cycling, domestique)]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>[david, boreanaz, 's, first, paid, acting, app...</td>\n",
              "      <td>[(david, boreanaz), (boreanaz, 's), ('s, first...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333414 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               token_text  \\\n",
              "304501  [1979-80, buffalo, sabres, nhl, 32, 1880, 74, ...   \n",
              "162313  [diseases, lentils, in, culture, lentils, are,...   \n",
              "336845  [railroads, ,, like, the, lehigh, valley, rail...   \n",
              "150625  [an, example, of, this, would, be, an, individ...   \n",
              "40240   [both, the, matanuska, and, susitna, rivers, h...   \n",
              "...                                                   ...   \n",
              "259178  [after, the, germans, invaded, norway, in, apr...   \n",
              "365838  [july, 28, -, henry, bennet, ,, 1st, earl, of,...   \n",
              "131932  [pancake, restaurants, are, popular, family, r...   \n",
              "146867                           [a, cycling, domestique]   \n",
              "121958  [david, boreanaz, 's, first, paid, acting, app...   \n",
              "\n",
              "                                                   bigram  length  \n",
              "304501  [(1979-80, buffalo), (buffalo, sabres), (sabre...      15  \n",
              "162313  [(diseases, lentils), (lentils, in), (in, cult...      25  \n",
              "336845  [(railroads, ,), (,, like), (like, the), (the,...      19  \n",
              "150625  [(an, example), (example, of), (of, this), (th...      21  \n",
              "40240   [(both, the), (the, matanuska), (matanuska, an...       8  \n",
              "...                                                   ...     ...  \n",
              "259178  [(after, the), (the, germans), (germans, invad...      12  \n",
              "365838  [(july, 28), (28, -), (-, henry), (henry, benn...      14  \n",
              "131932  [(pancake, restaurants), (restaurants, are), (...      15  \n",
              "146867              [(a, cycling), (cycling, domestique)]       2  \n",
              "121958  [(david, boreanaz), (boreanaz, 's), ('s, first...      30  \n",
              "\n",
              "[333414 rows x 3 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do2kf1t0L1KG",
        "outputId": "21a83012-455f-45a8-8b9a-980aa581afe9"
      },
      "source": [
        "combined_X_train = X_train[\"token_text\"] + X_train['bigram']\n",
        "combined_X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "304501    [1979-80, buffalo, sabres, nhl, 32, 1880, 74, ...\n",
              "162313    [diseases, lentils, in, culture, lentils, are,...\n",
              "336845    [railroads, ,, like, the, lehigh, valley, rail...\n",
              "150625    [an, example, of, this, would, be, an, individ...\n",
              "40240     [both, the, matanuska, and, susitna, rivers, h...\n",
              "dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2wVw50tL1KG",
        "outputId": "89f44b33-b0a7-4559-abd1-c0abd766c1d7"
      },
      "source": [
        "num_features = 250    \n",
        "min_word_count = 3    \n",
        "num_workers = 2       \n",
        "context = 5           \n",
        "downsampling = 1e-4 \n",
        "\n",
        "model = Word2Vec(combined_X_train, vector_size=num_features, sg=1, hs=0,workers=num_workers, min_count=min_word_count,\n",
        "                window=context, sample=downsampling, negative=5)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=435448, vector_size=250, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70L1aIYJL1KH",
        "outputId": "f4ae5ba7-3ed9-4219-9704-6b9218bac976"
      },
      "source": [
        "vocab = model.wv.index_to_key\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "435448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REGHMwr-L1KH"
      },
      "source": [
        "# vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn5Z39nxL1KH"
      },
      "source": [
        "# ((model.wv[('in', 'the')][0] + model.wv[('in', 'the')][1])/2).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA3Fq3IPL1KH"
      },
      "source": [
        "# model.vector_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jCFQ4THL1KH"
      },
      "source": [
        "def sen_to_vect(row, model):\n",
        "    nwords = 0\n",
        "    sent_vector = np.zeros(model.vector_size, dtype=\"float32\")\n",
        "    vocab = model.wv.index_to_key\n",
        "    # Sum up all words vectors that are know to the model\n",
        "    for word in row:\n",
        "        if word in vocab:\n",
        "#             bi = (model.wv[word][0] + model.wv[word][1]) / 2\n",
        "            sent_vector += model.wv[word]\n",
        "            nwords +=1\n",
        "\n",
        "    # Now get the average\n",
        "    if nwords > 0:\n",
        "        sent_vector /= nwords\n",
        "    return sent_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQn7KwZkL1KI",
        "outputId": "d93d5be3-66ae-4fcc-c01b-81e3e6f47661"
      },
      "source": [
        "sen_to_vect(X_train[\"token_text\"][0], model).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(250,)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUBw1CZ5L1KI"
      },
      "source": [
        "def sen_to_vect_ngram(row, model):\n",
        "    nwords = 0\n",
        "    sent_vector = np.zeros(model.vector_size, dtype=\"float32\")\n",
        "    vocab = model.wv.index_to_key\n",
        "    # Sum up all words vectors that are know to the model\n",
        "    for word in row:\n",
        "        if word in vocab:\n",
        "            bi = (model.wv[word][0] + model.wv[word][1]) / 2\n",
        "            sent_vector += bi\n",
        "            nwords +=1\n",
        "\n",
        "    # Now get the average\n",
        "    if nwords > 0:\n",
        "        sent_vector /= nwords\n",
        "    return sent_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COKb9XJ-L1KI",
        "outputId": "7a20f1a5-c476-4f72-8a02-1f8ee7ab0002"
      },
      "source": [
        "sen_to_vect_ngram(X_train[\"bigram\"][0], model).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(250,)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o__x6DNyL1KI",
        "outputId": "68078685-5830-44a9-fb68-b113b5580631"
      },
      "source": [
        "w2v_df = pd.DataFrame()\n",
        "w2v_df['sentence_vectors'] = X_train[\"token_text\"].apply(lambda x: sen_to_vect(x, model))\n",
        "# w2v_df['sentence_vectors_bigram'] = X_train[\"bigram\"].apply(lambda x: sen_to_vect_ngram(x, model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-31-8a5bcc42f697>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mw2v_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw2v_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_vectors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msen_to_vect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# w2v_df['sentence_vectors_bigram'] = X_train[\"bigram\"].apply(lambda x: sen_to_vect_ngram(x, model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4198\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4200\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32m<ipython-input-31-8a5bcc42f697>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mw2v_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mw2v_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_vectors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msen_to_vect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# w2v_df['sentence_vectors_bigram'] = X_train[\"bigram\"].apply(lambda x: sen_to_vect_ngram(x, model))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-24-86789b519532>\u001b[0m in \u001b[0;36msen_to_vect\u001b[1;34m(row, model)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#             bi = (model.wv[word][0] + model.wv[word][1]) / 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0msent_vector\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mnwords\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \"\"\"Get vector representation of `key_or_keys`.\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgs6eRd5L1KJ"
      },
      "source": [
        "w2v_df['sentence_vectors_bigram'] = X_train[\"bigram\"].apply(lambda x: sen_to_vect_ngram(x, model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7p0KHMeL1KJ"
      },
      "source": [
        "w2v_df.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AnsAtr5L1KJ"
      },
      "source": [
        "w2v_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYd30FXCL1KJ"
      },
      "source": [
        "index=[]\n",
        "for i in range(model.vector_size):\n",
        "    w2v_df[f'w2v_{i}'] = w2v_df['sentence_vectors'].apply(lambda x: x[i])\n",
        "    index.append(f'w2v_{i}') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45MgZobYL1KJ"
      },
      "source": [
        "# w2v_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3MhwOfVL1KJ"
      },
      "source": [
        "w2v_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVfv9DtNL1KJ"
      },
      "source": [
        "w2v_df_train = w2v_df.iloc[:,1:]\n",
        "w2v_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RzRrNvxL1KK"
      },
      "source": [
        "# process the test data\n",
        "w2v_df_test = pd.DataFrame()\n",
        "w2v_df_test['sentence_vectors'] = X_test[\"token_text\"].apply(lambda x: sen_to_vect(x, model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsE2DeodL1KK"
      },
      "source": [
        "index=[]\n",
        "for i in range(model.vector_size):\n",
        "    w2v_df_test[f'w2v_{i}'] = w2v_df_test['sentence_vectors'].apply(lambda x: x[i])\n",
        "    index.append(f'w2v_{i}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VgOAW6AL1KK"
      },
      "source": [
        "w2v_df_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckXUVVTrL1KK"
      },
      "source": [
        "w2v_df_test = w2v_df_test.iloc[:,1:]\n",
        "w2v_df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOYmNs8UL1KK"
      },
      "source": [
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(w2v_df_train, y_train)\n",
        "y_lr_pred_text = lr.predict(w2v_df_test)\n",
        "lr_tfidf_text = accuracy_score(y_test, y_lr_pred_text)\n",
        "lr_tfidf_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9M3T3u1L1KL"
      },
      "source": [
        "# X_train[\"length\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JzNsOG9L1KL"
      },
      "source": [
        "# X_test[\"length\"].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0wnZVBgL1KL"
      },
      "source": [
        "# w2v_df_train[\"length\"] = X_train[\"length\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijP-lbNL1KL"
      },
      "source": [
        "# w2v_df_test[\"length\"] = X_test[\"length\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypseh9vtL1KM"
      },
      "source": [
        "# w2v_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUuxCN2TL1KM"
      },
      "source": [
        "# lr = LogisticRegression(max_iter=10000)\n",
        "# lr.fit(w2v_df_train, y_train)\n",
        "# y_lr_pred_text = lr.predict(w2v_df_test)\n",
        "# lr_tfidf_text = accuracy_score(y_test, y_lr_pred_text)\n",
        "# lr_tfidf_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5hpoDH_L1KM"
      },
      "source": [
        "# svc = LinearSVC(max_iter=10000)\n",
        "# svc.fit(w2v_df_train, y_train)\n",
        "# y_svc_pred_svc = svc.predict(w2v_df_test)\n",
        "# svc_w2v_text = accuracy_score(y_test, y_svc_pred_svc)\n",
        "# svc_w2v_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeSWrl2kL1KM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJFwKQ2CL1KM"
      },
      "source": [
        "text = ['cant railway station','citadel hotel',' police stn']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1lPyHhxL1KM"
      },
      "source": [
        "bigram = []\n",
        "for line in text:\n",
        "    token = data.iloc[0,3]\n",
        "    bigram.extend((ngrams(token, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl9mh-ghL1KN"
      },
      "source": [
        "bigram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOMM3D5nL1KN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgiOnOlL1KN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uby3_IBFL1KN"
      },
      "source": [
        "# define training data\n",
        "# sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],['this', 'is', 'the', 'second', 'sentence'],\n",
        "#             ['yet', 'another', 'sentence'], ['one', 'more', 'sentence'],['and', 'the', 'final', 'sentence']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoVvgQT4L1KN"
      },
      "source": [
        "# train model\n",
        "# model1 = Word2Vec(sentences, min_count=1)\n",
        "# summarize the loaded model\n",
        "# print(model1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KluuF2pDL1KN"
      },
      "source": [
        "# summarize vocabulary\n",
        "# model_voc = model1.wv.index_to_key\n",
        "# print(model_voc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oEqY8Fo_L1KO"
      },
      "source": [
        "# access vector for one word\n",
        "# print(model1.wv['the'].size)\n",
        "# print(model1.wv['the'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNob5r5EL1KO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxRFSzgWL1KO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE5CqRGTL1KO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pziYtVlOL1KO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAgvVc-dL1KO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLoTLn9NL1KP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETH7bO2yL1KP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb_sXdSOL1KP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}